{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 导出ONNX模型\n",
        "\n",
        "把原生Pytorch训练得到的图像分类模型，导出为ONNX格式，用于后续在ONNX Runtime推理引擎上部署。\n",
        "\n",
        "同济子豪兄 https://space.bilibili.com/1900783\n",
        "\n",
        "代码运行云GPU平台：https://featurize.cn/?s=d7ce99f842414bfcaea5662a97581bd1\n",
        "\n",
        "2022-8-22"
      ],
      "metadata": {},
      "id": "1c02c91b-e604-4778-b626-b06b350891de"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 导入工具包"
      ],
      "metadata": {},
      "id": "aab08f57-14e2-44bc-8562-51c7be68f074"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "\n",
        "# 有 GPU 就用 GPU，没有就用 CPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('device', device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "device cuda:0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1674979938985
        }
      },
      "id": "f9baf99e-744e-462d-94b4-f3653cb743ca"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 载入ImageNet预训练图像分类模型"
      ],
      "metadata": {},
      "id": "83ca3195-6800-4c89-98a7-3fb0c44ec329"
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "model = model.eval().to(device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/jupyter_env/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/anaconda/envs/jupyter_env/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/azureuser/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0.00/44.7M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "517f6fb38e2a4bb0822ea5c1fb40783b"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1674979941084
        }
      },
      "id": "04824a4e-29ef-4048-af6e-e2442e388b69"
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 3, 256, 256).to(device)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1674979943401
        }
      },
      "id": "f3e41561-1d86-4f1d-b98d-c19373635bd8"
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(x)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {},
      "id": "6fa9b2ec-ec96-419e-a289-5615ea57b00b"
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "torch.Size([1, 1000])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {},
      "id": "bb5ffda8-26af-4d9b-8770-3de9de27958c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch模型转ONNX模型"
      ],
      "metadata": {},
      "id": "8b8bb112-e3d4-4abe-ab51-b09ed29ef682"
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 3, 256, 256).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    torch.onnx.export(\n",
        "        model,                  # 要转换的模型\n",
        "        x,                      # 模型的任意一组输入\n",
        "        'resnet18.onnx',        # 导出的 ONNX 文件名\n",
        "        opset_version=11,       # ONNX 算子集版本\n",
        "        input_names=['input'],  # 输入 Tensor 的名称（自己起名字）\n",
        "        output_names=['output'] # 输出 Tensor 的名称（自己起名字）\n",
        "    ) "
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1674980225346
        }
      },
      "id": "4adf4e24-93f5-4467-b011-e69c45d45bd3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 验证onnx模型导出成功"
      ],
      "metadata": {},
      "id": "9f30be68-1c30-43cd-be36-541b3035d933"
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "# 读取 ONNX 模型\n",
        "onnx_model = onnx.load('resnet18.onnx')\n",
        "\n",
        "# 检查模型格式是否正确\n",
        "onnx.checker.check_model(onnx_model)\n",
        "\n",
        "print('无报错，onnx模型载入成功')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "无报错，onnx模型载入成功\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1674980233543
        }
      },
      "id": "067ce090-879a-4b05-af90-c7da47d84cc2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 以可读的形式打印计算图"
      ],
      "metadata": {},
      "id": "9fa98064-6ac5-4072-a331-8513b3e29a03"
    },
    {
      "cell_type": "code",
      "source": [
        "print(onnx.helper.printable_graph(onnx_model.graph))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "graph torch_jit (\n  %input[FLOAT, 1x3x256x256]\n) initializers (\n  %fc.weight[FLOAT, 1000x512]\n  %fc.bias[FLOAT, 1000]\n  %onnx::Conv_193[FLOAT, 64x3x7x7]\n  %onnx::Conv_194[FLOAT, 64]\n  %onnx::Conv_196[FLOAT, 64x64x3x3]\n  %onnx::Conv_197[FLOAT, 64]\n  %onnx::Conv_199[FLOAT, 64x64x3x3]\n  %onnx::Conv_200[FLOAT, 64]\n  %onnx::Conv_202[FLOAT, 64x64x3x3]\n  %onnx::Conv_203[FLOAT, 64]\n  %onnx::Conv_205[FLOAT, 64x64x3x3]\n  %onnx::Conv_206[FLOAT, 64]\n  %onnx::Conv_208[FLOAT, 128x64x3x3]\n  %onnx::Conv_209[FLOAT, 128]\n  %onnx::Conv_211[FLOAT, 128x128x3x3]\n  %onnx::Conv_212[FLOAT, 128]\n  %onnx::Conv_214[FLOAT, 128x64x1x1]\n  %onnx::Conv_215[FLOAT, 128]\n  %onnx::Conv_217[FLOAT, 128x128x3x3]\n  %onnx::Conv_218[FLOAT, 128]\n  %onnx::Conv_220[FLOAT, 128x128x3x3]\n  %onnx::Conv_221[FLOAT, 128]\n  %onnx::Conv_223[FLOAT, 256x128x3x3]\n  %onnx::Conv_224[FLOAT, 256]\n  %onnx::Conv_226[FLOAT, 256x256x3x3]\n  %onnx::Conv_227[FLOAT, 256]\n  %onnx::Conv_229[FLOAT, 256x128x1x1]\n  %onnx::Conv_230[FLOAT, 256]\n  %onnx::Conv_232[FLOAT, 256x256x3x3]\n  %onnx::Conv_233[FLOAT, 256]\n  %onnx::Conv_235[FLOAT, 256x256x3x3]\n  %onnx::Conv_236[FLOAT, 256]\n  %onnx::Conv_238[FLOAT, 512x256x3x3]\n  %onnx::Conv_239[FLOAT, 512]\n  %onnx::Conv_241[FLOAT, 512x512x3x3]\n  %onnx::Conv_242[FLOAT, 512]\n  %onnx::Conv_244[FLOAT, 512x256x1x1]\n  %onnx::Conv_245[FLOAT, 512]\n  %onnx::Conv_247[FLOAT, 512x512x3x3]\n  %onnx::Conv_248[FLOAT, 512]\n  %onnx::Conv_250[FLOAT, 512x512x3x3]\n  %onnx::Conv_251[FLOAT, 512]\n) {\n  %/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [7, 7], pads = [3, 3, 3, 3], strides = [2, 2]](%input, %onnx::Conv_193, %onnx::Conv_194)\n  %/relu/Relu_output_0 = Relu(%/conv1/Conv_output_0)\n  %/maxpool/MaxPool_output_0 = MaxPool[ceil_mode = 0, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/relu/Relu_output_0)\n  %/layer1/layer1.0/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/maxpool/MaxPool_output_0, %onnx::Conv_196, %onnx::Conv_197)\n  %/layer1/layer1.0/relu/Relu_output_0 = Relu(%/layer1/layer1.0/conv1/Conv_output_0)\n  %/layer1/layer1.0/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer1/layer1.0/relu/Relu_output_0, %onnx::Conv_199, %onnx::Conv_200)\n  %/layer1/layer1.0/Add_output_0 = Add(%/layer1/layer1.0/conv2/Conv_output_0, %/maxpool/MaxPool_output_0)\n  %/layer1/layer1.0/relu_1/Relu_output_0 = Relu(%/layer1/layer1.0/Add_output_0)\n  %/layer1/layer1.1/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer1/layer1.0/relu_1/Relu_output_0, %onnx::Conv_202, %onnx::Conv_203)\n  %/layer1/layer1.1/relu/Relu_output_0 = Relu(%/layer1/layer1.1/conv1/Conv_output_0)\n  %/layer1/layer1.1/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer1/layer1.1/relu/Relu_output_0, %onnx::Conv_205, %onnx::Conv_206)\n  %/layer1/layer1.1/Add_output_0 = Add(%/layer1/layer1.1/conv2/Conv_output_0, %/layer1/layer1.0/relu_1/Relu_output_0)\n  %/layer1/layer1.1/relu_1/Relu_output_0 = Relu(%/layer1/layer1.1/Add_output_0)\n  %/layer2/layer2.0/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/layer1/layer1.1/relu_1/Relu_output_0, %onnx::Conv_208, %onnx::Conv_209)\n  %/layer2/layer2.0/relu/Relu_output_0 = Relu(%/layer2/layer2.0/conv1/Conv_output_0)\n  %/layer2/layer2.0/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer2/layer2.0/relu/Relu_output_0, %onnx::Conv_211, %onnx::Conv_212)\n  %/layer2/layer2.0/downsample/downsample.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%/layer1/layer1.1/relu_1/Relu_output_0, %onnx::Conv_214, %onnx::Conv_215)\n  %/layer2/layer2.0/Add_output_0 = Add(%/layer2/layer2.0/conv2/Conv_output_0, %/layer2/layer2.0/downsample/downsample.0/Conv_output_0)\n  %/layer2/layer2.0/relu_1/Relu_output_0 = Relu(%/layer2/layer2.0/Add_output_0)\n  %/layer2/layer2.1/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer2/layer2.0/relu_1/Relu_output_0, %onnx::Conv_217, %onnx::Conv_218)\n  %/layer2/layer2.1/relu/Relu_output_0 = Relu(%/layer2/layer2.1/conv1/Conv_output_0)\n  %/layer2/layer2.1/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer2/layer2.1/relu/Relu_output_0, %onnx::Conv_220, %onnx::Conv_221)\n  %/layer2/layer2.1/Add_output_0 = Add(%/layer2/layer2.1/conv2/Conv_output_0, %/layer2/layer2.0/relu_1/Relu_output_0)\n  %/layer2/layer2.1/relu_1/Relu_output_0 = Relu(%/layer2/layer2.1/Add_output_0)\n  %/layer3/layer3.0/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/layer2/layer2.1/relu_1/Relu_output_0, %onnx::Conv_223, %onnx::Conv_224)\n  %/layer3/layer3.0/relu/Relu_output_0 = Relu(%/layer3/layer3.0/conv1/Conv_output_0)\n  %/layer3/layer3.0/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer3/layer3.0/relu/Relu_output_0, %onnx::Conv_226, %onnx::Conv_227)\n  %/layer3/layer3.0/downsample/downsample.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%/layer2/layer2.1/relu_1/Relu_output_0, %onnx::Conv_229, %onnx::Conv_230)\n  %/layer3/layer3.0/Add_output_0 = Add(%/layer3/layer3.0/conv2/Conv_output_0, %/layer3/layer3.0/downsample/downsample.0/Conv_output_0)\n  %/layer3/layer3.0/relu_1/Relu_output_0 = Relu(%/layer3/layer3.0/Add_output_0)\n  %/layer3/layer3.1/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer3/layer3.0/relu_1/Relu_output_0, %onnx::Conv_232, %onnx::Conv_233)\n  %/layer3/layer3.1/relu/Relu_output_0 = Relu(%/layer3/layer3.1/conv1/Conv_output_0)\n  %/layer3/layer3.1/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer3/layer3.1/relu/Relu_output_0, %onnx::Conv_235, %onnx::Conv_236)\n  %/layer3/layer3.1/Add_output_0 = Add(%/layer3/layer3.1/conv2/Conv_output_0, %/layer3/layer3.0/relu_1/Relu_output_0)\n  %/layer3/layer3.1/relu_1/Relu_output_0 = Relu(%/layer3/layer3.1/Add_output_0)\n  %/layer4/layer4.0/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%/layer3/layer3.1/relu_1/Relu_output_0, %onnx::Conv_238, %onnx::Conv_239)\n  %/layer4/layer4.0/relu/Relu_output_0 = Relu(%/layer4/layer4.0/conv1/Conv_output_0)\n  %/layer4/layer4.0/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer4/layer4.0/relu/Relu_output_0, %onnx::Conv_241, %onnx::Conv_242)\n  %/layer4/layer4.0/downsample/downsample.0/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [2, 2]](%/layer3/layer3.1/relu_1/Relu_output_0, %onnx::Conv_244, %onnx::Conv_245)\n  %/layer4/layer4.0/Add_output_0 = Add(%/layer4/layer4.0/conv2/Conv_output_0, %/layer4/layer4.0/downsample/downsample.0/Conv_output_0)\n  %/layer4/layer4.0/relu_1/Relu_output_0 = Relu(%/layer4/layer4.0/Add_output_0)\n  %/layer4/layer4.1/conv1/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer4/layer4.0/relu_1/Relu_output_0, %onnx::Conv_247, %onnx::Conv_248)\n  %/layer4/layer4.1/relu/Relu_output_0 = Relu(%/layer4/layer4.1/conv1/Conv_output_0)\n  %/layer4/layer4.1/conv2/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%/layer4/layer4.1/relu/Relu_output_0, %onnx::Conv_250, %onnx::Conv_251)\n  %/layer4/layer4.1/Add_output_0 = Add(%/layer4/layer4.1/conv2/Conv_output_0, %/layer4/layer4.0/relu_1/Relu_output_0)\n  %/layer4/layer4.1/relu_1/Relu_output_0 = Relu(%/layer4/layer4.1/Add_output_0)\n  %/avgpool/GlobalAveragePool_output_0 = GlobalAveragePool(%/layer4/layer4.1/relu_1/Relu_output_0)\n  %/Flatten_output_0 = Flatten[axis = 1](%/avgpool/GlobalAveragePool_output_0)\n  %output = Gemm[alpha = 1, beta = 1, transB = 1](%/Flatten_output_0, %fc.weight, %fc.bias)\n  return %output\n}\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1674980236860
        }
      },
      "id": "333c59c1-6118-44e1-b892-e0a58d47cff1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 使用Netron对onnx模型可视化\n",
        "\n",
        "https://netron.app"
      ],
      "metadata": {},
      "id": "a989bf23-0d3a-4427-bf18-5b8a08a8dd64"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "0c424032-6fe5-4e78-b118-1fd993d6ebb4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}