{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 迁移学习微调训练图像分类模型\n",
        "\n",
        "在自己的图像分类数据集上，使用ImageNet预训练图像分类模型初始化，改动分类层，迁移学习微调训练\n",
        "\n",
        "同济子豪兄：https://space.bilibili.com/1900783\n",
        "\n",
        "[代码运行云GPU环境](https://featurize.cn/?s=d7ce99f842414bfcaea5662a97581bd1)：GPU RTX 3060、CUDA v11.2"
      ],
      "metadata": {},
      "id": "4a36abc9-47b6-4e9a-8d2c-330e64012db2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 导入工具包"
      ],
      "metadata": {},
      "id": "0d9c174f-33c0-44fa-af53-14237d35b37d"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 忽略烦人的红色提示\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# 获取计算硬件\n",
        "# 有 GPU 就用 GPU，没有就用 CPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('device', device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "device cuda:0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1674190515397
        }
      },
      "id": "6b35d923-b9e9-4ea4-914a-5bf05b93a2b5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 图像预处理"
      ],
      "metadata": {},
      "id": "4e9499c1-0594-48b8-80f0-e7fdbc30dbe3"
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# 训练集图像预处理：缩放裁剪、图像增强、转 Tensor、归一化\n",
        "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                     ])\n",
        "\n",
        "# 测试集图像预处理-RCTN：缩放、裁剪、转 Tensor、归一化\n",
        "test_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                     transforms.CenterCrop(224),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(\n",
        "                                         mean=[0.485, 0.456, 0.406], \n",
        "                                         std=[0.229, 0.224, 0.225])\n",
        "                                    ])"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1674190515754
        }
      },
      "id": "81f0ca03-de86-450d-a47e-6f0e7c19d97a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 载入图像分类数据集"
      ],
      "metadata": {},
      "id": "1d059c79-5b67-49fe-9baa-1bcd363208dc"
    },
    {
      "cell_type": "code",
      "source": [
        "# 数据集文件夹路径\n",
        "dataset_dir = 'fruit30_split'"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1674190516261
        }
      },
      "id": "5fd21e05-6cd0-4e06-a0f1-a029a79ddf86"
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = os.path.join(dataset_dir, 'train')\n",
        "test_path = os.path.join(dataset_dir, 'val')\n",
        "print('训练集路径', train_path)\n",
        "print('测试集路径', test_path)\n",
        "\n",
        "from torchvision import datasets\n",
        "# 载入训练集\n",
        "train_dataset = datasets.ImageFolder(train_path, train_transform)\n",
        "# 载入测试集\n",
        "test_dataset = datasets.ImageFolder(test_path, test_transform)\n",
        "\n",
        "print('训练集图像数量', len(train_dataset))\n",
        "print('类别个数', len(train_dataset.classes))\n",
        "print('各类别名称', train_dataset.classes)\n",
        "print('测试集图像数量', len(test_dataset))\n",
        "print('类别个数', len(test_dataset.classes))\n",
        "print('各类别名称', test_dataset.classes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "训练集路径 fruit30_split/train\n测试集路径 fruit30_split/val\n训练集图像数量 4375\n类别个数 30\n各类别名称 ['哈密瓜', '圣女果', '山竹', '杨梅', '柚子', '柠檬', '桂圆', '梨', '椰子', '榴莲', '火龙果', '猕猴桃', '石榴', '砂糖橘', '胡萝卜', '脐橙', '芒果', '苦瓜', '苹果-红', '苹果-青', '草莓', '荔枝', '菠萝', '葡萄-白', '葡萄-红', '西瓜', '西红柿', '车厘子', '香蕉', '黄瓜']\n测试集图像数量 1078\n类别个数 30\n各类别名称 ['哈密瓜', '圣女果', '山竹', '杨梅', '柚子', '柠檬', '桂圆', '梨', '椰子', '榴莲', '火龙果', '猕猴桃', '石榴', '砂糖橘', '胡萝卜', '脐橙', '芒果', '苦瓜', '苹果-红', '苹果-青', '草莓', '荔枝', '菠萝', '葡萄-白', '葡萄-红', '西瓜', '西红柿', '车厘子', '香蕉', '黄瓜']\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1674190518454
        }
      },
      "id": "dcf6544a-6af5-4b07-93df-d863157b9290"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 类别和索引号 映射字典"
      ],
      "metadata": {},
      "id": "f74e98be-4648-4d34-9e6c-273a55127b4d"
    },
    {
      "cell_type": "code",
      "source": [
        "# 各类别名称\n",
        "class_names = train_dataset.classes\n",
        "n_class = len(class_names)\n",
        "# 映射关系：类别 到 索引号\n",
        "train_dataset.class_to_idx\n",
        "# 映射关系：索引号 到 类别\n",
        "idx_to_labels = {y:x for x,y in train_dataset.class_to_idx.items()}"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1674190522920
        }
      },
      "id": "0f737200-3afd-46f7-9c42-52c66829572e"
    },
    {
      "cell_type": "code",
      "source": [
        "idx_to_labels"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "{0: '哈密瓜',\n 1: '圣女果',\n 2: '山竹',\n 3: '杨梅',\n 4: '柚子',\n 5: '柠檬',\n 6: '桂圆',\n 7: '梨',\n 8: '椰子',\n 9: '榴莲',\n 10: '火龙果',\n 11: '猕猴桃',\n 12: '石榴',\n 13: '砂糖橘',\n 14: '胡萝卜',\n 15: '脐橙',\n 16: '芒果',\n 17: '苦瓜',\n 18: '苹果-红',\n 19: '苹果-青',\n 20: '草莓',\n 21: '荔枝',\n 22: '菠萝',\n 23: '葡萄-白',\n 24: '葡萄-红',\n 25: '西瓜',\n 26: '西红柿',\n 27: '车厘子',\n 28: '香蕉',\n 29: '黄瓜'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1674190527645
        }
      },
      "id": "d0baa451-a3c8-456a-a1ad-ea814dc9958c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 定义数据加载器DataLoader"
      ],
      "metadata": {},
      "id": "329d3824-e6bb-4f50-9802-f073d9151311"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# 训练集的数据加载器\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=True,\n",
        "                          num_workers=4\n",
        "                         )\n",
        "\n",
        "# 测试集的数据加载器\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         shuffle=False,\n",
        "                         num_workers=4\n",
        "                        )"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1674190555938
        }
      },
      "id": "a787702d-61c6-41af-9cbd-19bc5d3baae7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 导入训练需使用的工具包"
      ],
      "metadata": {},
      "id": "80b52d04-a791-4feb-8b57-af98b253ebba"
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1674190558462
        }
      },
      "id": "684da643-5a88-4ba2-b49c-5dc98b35100e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 选择迁移学习训练方式\n",
        "\n",
        "斯坦福CS231N【迁移学习】中文精讲：https://www.bilibili.com/video/BV1K7411W7So\n",
        "\n",
        "斯坦福CS231N【迁移学习】官方笔记：https://cs231n.github.io/transfer-learning/"
      ],
      "metadata": {},
      "id": "375b9c90-160f-451f-a46b-6e846424cc0a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 选择一：只微调训练模型最后一层（全连接分类层）"
      ],
      "metadata": {},
      "id": "d146006e-6bb2-4b34-8530-6c762398938e"
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True) # 载入预训练模型\n",
        "\n",
        "# 修改全连接层，使得全连接层的输出与当前数据集类别数对应\n",
        "# 新建的层默认 requires_grad=True\n",
        "model.fc = nn.Linear(model.fc.in_features, n_class)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1674190561402
        }
      },
      "id": "15772d27-7a9c-43e6-8750-5080e6085403"
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "Linear(in_features=512, out_features=30, bias=True)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1674190563568
        }
      },
      "id": "7831dc08-e59e-4013-8390-b786fae0ed0c"
    },
    {
      "cell_type": "code",
      "source": [
        "# 只微调训练最后一层全连接层的参数，其它层冻结\n",
        "optimizer = optim.Adam(model.fc.parameters())"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1674190564963
        }
      },
      "id": "8456b4d8-1ca8-4725-9377-92e5224ffbf0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 选择二：微调训练所有层"
      ],
      "metadata": {},
      "id": "81bf28f7-07f6-493a-b358-318b1a187a30"
    },
    {
      "cell_type": "code",
      "source": [
        "# model = models.resnet18(pretrained=True) # 载入预训练模型\n",
        "\n",
        "# model.fc = nn.Linear(model.fc.in_features, n_class)\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters())"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {},
      "id": "e00e1a34-19b7-47c7-ad7b-1a88d93ef709"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 选择三：随机初始化模型全部权重，从头训练所有层"
      ],
      "metadata": {},
      "id": "3d831974-0425-4fe3-9eb0-1afc504b7bd2"
    },
    {
      "cell_type": "code",
      "source": [
        "# model = models.resnet18(pretrained=False) # 只载入模型结构，不载入预训练权重参数\n",
        "\n",
        "# model.fc = nn.Linear(model.fc.in_features, n_class)\n",
        "\n",
        "# optimizer = optim.Adam(model.parameters())"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {},
      "id": "209747a8-38a7-481d-a0f4-fa9fda035d62"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 训练配置"
      ],
      "metadata": {},
      "id": "6e92213d-d6d9-435f-a4c0-4bcdbdf7c6b8"
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "\n",
        "# 交叉熵损失函数\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "\n",
        "# 训练轮次 Epoch\n",
        "EPOCHS = 30\n",
        "\n",
        "# 学习率降低策略\n",
        "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1674190686621
        }
      },
      "id": "a5146eb0-f25e-400c-bbd6-e567f8aab8c9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 函数：在训练集上训练"
      ],
      "metadata": {},
      "id": "a36146f7-afb5-416e-a7d2-938c0fd6ab6a"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1674190688634
        }
      },
      "id": "a4fde230-042e-4e58-92eb-36d9febc8553"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_batch(images, labels):\n",
        "    '''\n",
        "    运行一个 batch 的训练，返回当前 batch 的训练日志\n",
        "    '''\n",
        "    \n",
        "    # 获得一个 batch 的数据和标注\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    outputs = model(images) # 输入模型，执行前向预测\n",
        "    loss = criterion(outputs, labels) # 计算当前 batch 中，每个样本的平均交叉熵损失函数值\n",
        "    \n",
        "    # 优化更新权重\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # 获取当前 batch 的标签类别和预测类别\n",
        "    _, preds = torch.max(outputs, 1) # 获得当前 batch 所有图像的预测类别\n",
        "    preds = preds.cpu().numpy()\n",
        "    loss = loss.detach().cpu().numpy()\n",
        "    outputs = outputs.detach().cpu().numpy()\n",
        "    labels = labels.detach().cpu().numpy()\n",
        "    \n",
        "    log_train = {}\n",
        "    log_train['epoch'] = epoch\n",
        "    log_train['batch'] = batch_idx\n",
        "    # 计算分类评估指标\n",
        "    log_train['train_loss'] = loss\n",
        "    log_train['train_accuracy'] = accuracy_score(labels, preds)\n",
        "    # log_train['train_precision'] = precision_score(labels, preds, average='macro')\n",
        "    # log_train['train_recall'] = recall_score(labels, preds, average='macro')\n",
        "    # log_train['train_f1-score'] = f1_score(labels, preds, average='macro')\n",
        "    \n",
        "    return log_train"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1674190689783
        }
      },
      "id": "c6511cc9-d9d8-4c67-9aed-e1c0ac14dbcb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 函数：在整个测试集上评估"
      ],
      "metadata": {},
      "id": "db850cdd-41eb-454a-957d-9af9dad9165b"
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_testset():\n",
        "    '''\n",
        "    在整个测试集上评估，返回分类评估指标日志\n",
        "    '''\n",
        "\n",
        "    loss_list = []\n",
        "    labels_list = []\n",
        "    preds_list = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader: # 生成一个 batch 的数据和标注\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images) # 输入模型，执行前向预测\n",
        "\n",
        "            # 获取整个测试集的标签类别和预测类别\n",
        "            _, preds = torch.max(outputs, 1) # 获得当前 batch 所有图像的预测类别\n",
        "            preds = preds.cpu().numpy()\n",
        "            loss = criterion(outputs, labels) # 由 logit，计算当前 batch 中，每个样本的平均交叉熵损失函数值\n",
        "            loss = loss.detach().cpu().numpy()\n",
        "            outputs = outputs.detach().cpu().numpy()\n",
        "            labels = labels.detach().cpu().numpy()\n",
        "\n",
        "            loss_list.append(loss)\n",
        "            labels_list.extend(labels)\n",
        "            preds_list.extend(preds)\n",
        "        \n",
        "    log_test = {}\n",
        "    log_test['epoch'] = epoch\n",
        "    \n",
        "    # 计算分类评估指标\n",
        "    log_test['test_loss'] = np.mean(loss)\n",
        "    log_test['test_accuracy'] = accuracy_score(labels_list, preds_list)\n",
        "    log_test['test_precision'] = precision_score(labels_list, preds_list, average='macro')\n",
        "    log_test['test_recall'] = recall_score(labels_list, preds_list, average='macro')\n",
        "    log_test['test_f1-score'] = f1_score(labels_list, preds_list, average='macro')\n",
        "    \n",
        "    return log_test"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1674190692619
        }
      },
      "id": "709a01fc-05c8-4c4e-abca-6fcded8c838a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 训练开始之前，记录日志"
      ],
      "metadata": {},
      "id": "8fdf43a5-2490-4772-9ed2-7e4e3025493f"
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 0\n",
        "batch_idx = 0\n",
        "best_test_accuracy = 0"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1674190695633
        }
      },
      "id": "fee46b5e-4175-4de2-86d3-4f6159b99dbd"
    },
    {
      "cell_type": "code",
      "source": [
        "# 训练日志-训练集\n",
        "df_train_log = pd.DataFrame()\n",
        "log_train = {}\n",
        "log_train['epoch'] = 0\n",
        "log_train['batch'] = 0\n",
        "images, labels = next(iter(train_loader))\n",
        "log_train.update(train_one_batch(images, labels))\n",
        "df_train_log = df_train_log.append(log_train, ignore_index=True)"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1674190700522
        }
      },
      "id": "3760c516-8301-4455-9eeb-c3eaa63ae249"
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_log"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "   batch  epoch  train_accuracy train_loss\n0    0.0    0.0          0.0625  3.4914072",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>batch</th>\n      <th>epoch</th>\n      <th>train_accuracy</th>\n      <th>train_loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0625</td>\n      <td>3.4914072</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1674190745605
        }
      },
      "id": "d11c0b7b-8482-4824-a46b-25c26ab804e5"
    },
    {
      "cell_type": "code",
      "source": [
        "# 训练日志-测试集\n",
        "df_test_log = pd.DataFrame()\n",
        "log_test = {}\n",
        "log_test['epoch'] = 0\n",
        "log_test.update(evaluate_testset())\n",
        "df_test_log = df_test_log.append(log_test, ignore_index=True)"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1674190767665
        }
      },
      "id": "af02f9ba-fa78-4164-8022-20205ff6e4d3"
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_log"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "   epoch  test_accuracy  test_f1-score  test_loss  test_precision  test_recall\n0    0.0       0.026902       0.009618   3.977199        0.009903     0.026654",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>test_accuracy</th>\n      <th>test_f1-score</th>\n      <th>test_loss</th>\n      <th>test_precision</th>\n      <th>test_recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.026902</td>\n      <td>0.009618</td>\n      <td>3.977199</td>\n      <td>0.009903</td>\n      <td>0.026654</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1674190767910
        }
      },
      "id": "5c8b30d7-3dd1-4b5e-98bf-8e07c1c334d1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 登录wandb\n",
        "\n",
        "1.安装 wandb：pip install wandb\n",
        "\n",
        "2.登录 wandb：在命令行中运行wandb login\n",
        "\n",
        "3.按提示复制粘贴API Key至命令行中"
      ],
      "metadata": {},
      "id": "82e5bd92-b32c-4e75-850f-26e39ed75a8a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 创建wandb可视化项目"
      ],
      "metadata": {},
      "id": "861f0565-b004-45e7-963d-93fd55f1df34"
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(project='fruit30', name=time.strftime('%m%d%H%M%S'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msorker0129\u001b[0m (\u001b[33msorker\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01667254325000158, max=1.0)…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a5a31cfb8c74fd988d8703ef28ae5a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.13.9"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/mnt/batch/tasks/shared/LS_root/mounts/clusters/buptst1/code/Users/buptst/Train_Custom_Dataset/图像分类/3-【Pytorch】迁移学习训练自己的图像分类模型/wandb/run-20230120_045741-ptta066j</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href=\"https://wandb.ai/sorker/fruit30/runs/ptta066j\" target=\"_blank\">0120045738</a></strong> to <a href=\"https://wandb.ai/sorker/fruit30\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href=\"https://wandb.ai/sorker/fruit30\" target=\"_blank\">https://wandb.ai/sorker/fruit30</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href=\"https://wandb.ai/sorker/fruit30/runs/ptta066j\" target=\"_blank\">https://wandb.ai/sorker/fruit30/runs/ptta066j</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/sorker/fruit30/runs/ptta066j?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>",
            "text/plain": "<wandb.sdk.wandb_run.Run at 0x7f7f737d29d0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1674190668695
        }
      },
      "id": "eb211f1a-64fc-497a-abf5-5639618a3784"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 运行训练"
      ],
      "metadata": {},
      "id": "733fec36-70de-4a8a-a985-57148fd36815"
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, EPOCHS+1):\n",
        "    \n",
        "    print(f'Epoch {epoch}/{EPOCHS}')\n",
        "    \n",
        "    ## 训练阶段\n",
        "    model.train()\n",
        "    for images, labels in tqdm(train_loader): # 获得一个 batch 的数据和标注\n",
        "        batch_idx += 1\n",
        "        log_train = train_one_batch(images, labels)\n",
        "        df_train_log = df_train_log.append(log_train, ignore_index=True)\n",
        "        wandb.log(log_train)\n",
        "        \n",
        "    lr_scheduler.step()\n",
        "\n",
        "    ## 测试阶段\n",
        "    model.eval()\n",
        "    log_test = evaluate_testset()\n",
        "    df_test_log = df_test_log.append(log_test, ignore_index=True)\n",
        "    wandb.log(log_test)\n",
        "    \n",
        "    # 保存最新的最佳模型文件\n",
        "    if log_test['test_accuracy'] > best_test_accuracy: \n",
        "        # 删除旧的最佳模型文件(如有)\n",
        "        old_best_checkpoint_path = 'checkpoints/best-{:.3f}.pth'.format(best_test_accuracy)\n",
        "        if os.path.exists(old_best_checkpoint_path):\n",
        "            os.remove(old_best_checkpoint_path)\n",
        "        # 保存新的最佳模型文件\n",
        "        new_best_checkpoint_path = 'checkpoints/best-{:.3f}.pth'.format(log_test['test_accuracy'])\n",
        "        torch.save(model, new_best_checkpoint_path)\n",
        "        print('保存新的最佳模型', 'checkpoints/best-{:.3f}.pth'.format(best_test_accuracy))\n",
        "        best_test_accuracy = log_test['test_accuracy']\n",
        "\n",
        "df_train_log.to_csv('训练日志-训练集.csv', index=False)\n",
        "df_test_log.to_csv('训练日志-测试集.csv', index=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/30\n保存新的最佳模型 checkpoints/best-0.000.pth\nEpoch 2/30\n保存新的最佳模型 checkpoints/best-0.714.pth\nEpoch 3/30\nEpoch 4/30\n保存新的最佳模型 checkpoints/best-0.807.pth\nEpoch 5/30\n保存新的最佳模型 checkpoints/best-0.842.pth\nEpoch 6/30\n保存新的最佳模型 checkpoints/best-0.849.pth\nEpoch 7/30\nEpoch 8/30\n保存新的最佳模型 checkpoints/best-0.863.pth\nEpoch 9/30\nEpoch 10/30\nEpoch 11/30\nEpoch 12/30\nEpoch 13/30\n保存新的最佳模型 checkpoints/best-0.869.pth\nEpoch 14/30\nEpoch 15/30\nEpoch 16/30\n保存新的最佳模型 checkpoints/best-0.870.pth\nEpoch 17/30\n保存新的最佳模型 checkpoints/best-0.873.pth\nEpoch 18/30\nEpoch 19/30\nEpoch 20/30\n保存新的最佳模型 checkpoints/best-0.875.pth\nEpoch 21/30\nEpoch 22/30\nEpoch 23/30\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 137/137 [00:41<00:00,  3.31it/s]\n100%|██████████| 137/137 [00:40<00:00,  3.35it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.30it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.30it/s]\n100%|██████████| 137/137 [00:40<00:00,  3.40it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.31it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.27it/s]\n100%|██████████| 137/137 [00:40<00:00,  3.35it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.30it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.27it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.33it/s]\n100%|██████████| 137/137 [00:40<00:00,  3.40it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.33it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.33it/s]\n100%|██████████| 137/137 [00:40<00:00,  3.35it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.31it/s]\n100%|██████████| 137/137 [00:42<00:00,  3.20it/s]\n100%|██████████| 137/137 [00:40<00:00,  3.34it/s]\n100%|██████████| 137/137 [00:40<00:00,  3.35it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.32it/s]\n100%|██████████| 137/137 [00:42<00:00,  3.26it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.27it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.32it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.28it/s]\n100%|██████████| 137/137 [00:40<00:00,  3.35it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.29it/s]\n100%|██████████| 137/137 [00:40<00:00,  3.34it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.31it/s]\n100%|██████████| 137/137 [00:41<00:00,  3.29it/s]\n100%|██████████| 137/137 [00:42<00:00,  3.23it/s]\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1674192358311
        }
      },
      "id": "c630791f-3137-49cd-8e38-3a788f84ec54"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 在测试集上评价"
      ],
      "metadata": {},
      "id": "56bdafc8-fca1-48f1-8fea-e864c3293d74"
    },
    {
      "cell_type": "code",
      "source": [
        "# 载入最佳模型作为当前模型\n",
        "model = torch.load('checkpoints/best-{:.3f}.pth'.format(best_test_accuracy))"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1674192360346
        }
      },
      "id": "d6512f03-53ff-428a-bff4-d151a2c57796"
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "print(evaluate_testset())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'epoch': 30, 'test_loss': 0.22705007, 'test_accuracy': 0.8766233766233766, 'test_precision': 0.8806510388277452, 'test_recall': 0.8758097723733153, 'test_f1-score': 0.8753931066079548}\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1674192370308
        }
      },
      "id": "2238ad86-508f-4a86-affd-fa6f8016e9bb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 参考文档\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "\n",
        "https://www.bilibili.com/video/BV14J411X7Bb\n",
        "\n",
        "https://www.bilibili.com/video/BV1w4411u7ay"
      ],
      "metadata": {},
      "id": "44e39fa3-29c0-489a-854e-b4df1c1bcf57"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "40aa9ab1-70dc-4373-8f38-095553e9a953"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}