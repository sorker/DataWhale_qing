{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import math\n",
        "import requests\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms, utils, datasets, models\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "%matplotlib inline\n",
        "\n",
        "# 忽略烦人的红色提示\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# windows操作系统\n",
        "# plt.rcParams['font.sans-serif']=['SimHei']  # 用来正常显示中文标签\n",
        "matplotlib.rc(\"font\",family='SimHei') # 中文字体\n",
        "plt.rcParams['axes.unicode_minus']=False  # 用来正常显示负号"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1676008953327
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取计算硬件\n",
        "# 有 GPU 就用 GPU，没有就用 CPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('device', device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "device cuda:0\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676008953634
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 训练集图像预处理：缩放裁剪、图像增强、转 Tensor、归一化\n",
        "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                     ])\n",
        "\n",
        "# 测试集图像预处理-RCTN：缩放、裁剪、转 Tensor、归一化\n",
        "test_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                     transforms.CenterCrop(224),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(\n",
        "                                         mean=[0.485, 0.456, 0.406],\n",
        "                                         std=[0.229, 0.224, 0.225])\n",
        "                                    ])"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676008954638
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = './dataset/'\n",
        "train_path = os.path.join(dataset_dir, 'train')\n",
        "test_path = os.path.join(dataset_dir, 'test')\n",
        "# 载入训练集\n",
        "train_dataset = datasets.ImageFolder(train_path, train_transform)\n",
        "\n",
        "# 载入测试集\n",
        "test_dataset = datasets.ImageFolder(test_path, test_transform)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676008955394
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('训练集图像数量', len(train_dataset))\n",
        "print('类别个数', len(train_dataset.classes))\n",
        "print('各类别名称', train_dataset.classes)\n",
        "print('测试集图像数量', len(test_dataset))\n",
        "print('类别个数', len(test_dataset.classes))\n",
        "print('各类别名称', test_dataset.classes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "训练集图像数量 2000\n类别个数 3\n各类别名称 ['benign', 'melanoma', 'seborrheic_keratosis']\n测试集图像数量 600\n类别个数 3\n各类别名称 ['benign', 'melanoma', 'seborrheic_keratosis']\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676008956296
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 各类别名称\n",
        "class_names = train_dataset.classes\n",
        "n_class = len(class_names)\n",
        "# 映射关系：类别 到 索引号\n",
        "train_dataset.class_to_idx\n",
        "# 映射关系：索引号 到 类别\n",
        "idx_to_labels = {y:x for x,y in train_dataset.class_to_idx.items()}\n",
        "\n",
        "if not os.path.exists('idx_to_labels.npy'):\n",
        "    np.save('idx_to_labels.npy', idx_to_labels)\n",
        "if not os.path.exists('labels_to_idx.npy'):\n",
        "    np.save('labels_to_idx.npy', train_dataset.class_to_idx)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676008956496
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "# 训练集的数据加载器\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          shuffle=True,\n",
        "                          num_workers=4\n",
        "                         )\n",
        "\n",
        "# 测试集的数据加载器\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         shuffle=False,\n",
        "                         num_workers=4\n",
        "                        )"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676008957297
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = models.resnet18(pretrained=True) # 载入预训练模型\n",
        "model = torch.load('./checkpoints/best-0.695.pth')\n",
        "\n",
        "# 修改全连接层，使得全连接层的输出与当前数据集类别数对应\n",
        "# 新建的层默认 requires_grad=True\n",
        "model.fc = nn.Linear(model.fc.in_features, n_class)\n",
        "\n",
        "# 只微调训练最后一层全连接层的参数，其它层冻结\n",
        "# optimizer = optim.Adam(model.fc.parameters())\n",
        "\n",
        "# 微调训练所有层的参数\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676008993463
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "\n",
        "# 交叉熵损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 训练轮次 Epoch\n",
        "EPOCHS = 30\n",
        "\n",
        "# 学习率降低策略\n",
        "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676009005374
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  训练开始之前，记录日志\n",
        "# 初始化\n",
        "epoch = 0\n",
        "batch_idx = 0\n",
        "best_test_accuracy = 0"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676009005605
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_batch(images, labels, epoch=0, batch_idx=0):\n",
        "    '''\n",
        "    运行一个 batch 的训练，返回当前 batch 的训练日志\n",
        "    '''\n",
        "\n",
        "    # 获得一个 batch 的数据和标注\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    outputs = model(images) # 输入模型，执行前向预测\n",
        "    loss = criterion(outputs, labels) # 计算当前 batch 中，每个样本的平均交叉熵损失函数值\n",
        "\n",
        "    # 优化更新权重\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 获取当前 batch 的标签类别和预测类别\n",
        "    _, preds = torch.max(outputs, 1) # 获得当前 batch 所有图像的预测类别\n",
        "    preds = preds.cpu().numpy()\n",
        "    loss = loss.detach().cpu().numpy()\n",
        "    outputs = outputs.detach().cpu().numpy()\n",
        "    labels = labels.detach().cpu().numpy()\n",
        "\n",
        "    log_train = {}\n",
        "    log_train['epoch'] = epoch\n",
        "    log_train['batch'] = batch_idx\n",
        "    # 计算分类评估指标\n",
        "    log_train['train_loss'] = loss\n",
        "    log_train['train_accuracy'] = accuracy_score(labels, preds)\n",
        "    # log_train['train_precision'] = precision_score(labels, preds, average='macro')\n",
        "    # log_train['train_recall'] = recall_score(labels, preds, average='macro')\n",
        "    # log_train['train_f1-score'] = f1_score(labels, preds, average='macro')\n",
        "\n",
        "    return log_train"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676009007299
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_testset():\n",
        "    '''\n",
        "    在整个测试集上评估，返回分类评估指标日志\n",
        "    '''\n",
        "\n",
        "    loss_list = []\n",
        "    labels_list = []\n",
        "    preds_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader: # 生成一个 batch 的数据和标注\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images) # 输入模型，执行前向预测\n",
        "\n",
        "            # 获取整个测试集的标签类别和预测类别\n",
        "            _, preds = torch.max(outputs, 1) # 获得当前 batch 所有图像的预测类别\n",
        "            preds = preds.cpu().numpy()\n",
        "            loss = criterion(outputs, labels) # 由 logit，计算当前 batch 中，每个样本的平均交叉熵损失函数值\n",
        "            loss = loss.detach().cpu().numpy()\n",
        "            outputs = outputs.detach().cpu().numpy()\n",
        "            labels = labels.detach().cpu().numpy()\n",
        "\n",
        "            loss_list.append(loss)\n",
        "            labels_list.extend(labels)\n",
        "            preds_list.extend(preds)\n",
        "\n",
        "    log_test = {}\n",
        "    log_test['epoch'] = epoch\n",
        "\n",
        "    # 计算分类评估指标\n",
        "    log_test['test_loss'] = np.mean(loss)\n",
        "    log_test['test_accuracy'] = accuracy_score(labels_list, preds_list)\n",
        "    log_test['test_precision'] = precision_score(labels_list, preds_list, average='macro')\n",
        "    log_test['test_recall'] = recall_score(labels_list, preds_list, average='macro')\n",
        "    log_test['test_f1-score'] = f1_score(labels_list, preds_list, average='macro')\n",
        "\n",
        "    return log_test"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676009008487
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 训练日志-训练集\n",
        "df_train_log = pd.DataFrame()\n",
        "log_train = {}\n",
        "log_train['epoch'] = 0\n",
        "log_train['batch'] = 0\n",
        "images, labels = next(iter(train_loader))\n",
        "log_train.update(train_one_batch(images, labels, epoch, batch_idx))\n",
        "df_train_log = df_train_log.append(log_train, ignore_index=True)\n",
        "\n",
        "# 训练日志-测试集\n",
        "df_test_log = pd.DataFrame()\n",
        "log_test = {}\n",
        "log_test['epoch'] = 0\n",
        "log_test.update(evaluate_testset())\n",
        "df_test_log = df_test_log.append(log_test, ignore_index=True)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676009147716
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_log"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "   epoch  batch train_loss  train_accuracy\n0      0      0  1.1346545         0.53125",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>batch</th>\n      <th>train_loss</th>\n      <th>train_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1.1346545</td>\n      <td>0.53125</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1676009148226
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_log"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "   epoch  test_loss  test_accuracy  test_precision  test_recall  test_f1-score\n0    0.0   3.319799          0.655        0.218333     0.333333       0.263847",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>test_loss</th>\n      <th>test_accuracy</th>\n      <th>test_precision</th>\n      <th>test_recall</th>\n      <th>test_f1-score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>3.319799</td>\n      <td>0.655</td>\n      <td>0.218333</td>\n      <td>0.333333</td>\n      <td>0.263847</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1676009148464
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 登录wandb\n",
        "1.安装 wandb：pip install wandb\n",
        "2.登录 wandb：在命令行中运行wandb login\n",
        "3.按提示复制粘贴API Key至命令行中"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project='isic2017_1', name=time.strftime('%m%d%H%M%S'))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msorker0129\u001b[0m (\u001b[33msorker\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.13.10"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/mnt/batch/tasks/shared/LS_root/mounts/clusters/buptst1/code/Users/buptst/Train_Custom_Dataset/isic_learn/wandb/run-20230210_060549-508lzr6v</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/sorker/isic2017_1/runs/508lzr6v' target=\"_blank\">0210060547</a></strong> to <a href='https://wandb.ai/sorker/isic2017_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/sorker/isic2017_1' target=\"_blank\">https://wandb.ai/sorker/isic2017_1</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/sorker/isic2017_1/runs/508lzr6v' target=\"_blank\">https://wandb.ai/sorker/isic2017_1/runs/508lzr6v</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sorker/isic2017_1/runs/508lzr6v?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
            "text/plain": "<wandb.sdk.wandb_run.Run at 0x7f3ff73edeb0>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676009153445
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, EPOCHS+1):\n",
        "\n",
        "    print(f'Epoch {epoch}/{EPOCHS}')\n",
        "\n",
        "    ## 训练阶段\n",
        "    model.train()\n",
        "    for images, labels in tqdm(train_loader): # 获得一个 batch 的数据和标注\n",
        "        batch_idx += 1\n",
        "        log_train = train_one_batch(images, labels, epoch, batch_idx)\n",
        "        df_train_log = df_train_log.append(log_train, ignore_index=True)\n",
        "        wandb.log(log_train)\n",
        "\n",
        "    lr_scheduler.step()\n",
        "\n",
        "    ## 测试阶段\n",
        "    model.eval()\n",
        "    log_test = evaluate_testset()\n",
        "    df_test_log = df_test_log.append(log_test, ignore_index=True)\n",
        "    wandb.log(log_test)\n",
        "\n",
        "    # 保存最新的最佳模型文件\n",
        "    if log_test['test_accuracy'] > best_test_accuracy:\n",
        "        # 删除旧的最佳模型文件(如有)\n",
        "        old_best_checkpoint_path = 'checkpoints/best-{:.3f}.pth'.format(best_test_accuracy)\n",
        "        if os.path.exists(old_best_checkpoint_path):\n",
        "            os.remove(old_best_checkpoint_path)\n",
        "        # 保存新的最佳模型文件\n",
        "        new_best_checkpoint_path = 'checkpoints/best-{:.3f}.pth'.format(log_test['test_accuracy'])\n",
        "        torch.save(model, new_best_checkpoint_path)\n",
        "        print('保存新的最佳模型', 'checkpoints/best-{:.3f}.pth'.format(best_test_accuracy))\n",
        "        best_test_accuracy = log_test['test_accuracy']\n",
        "\n",
        "df_train_log.to_csv('训练日志-训练集.csv', index=False)\n",
        "df_test_log.to_csv('训练日志-测试集.csv', index=False)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/30\n保存新的最佳模型 checkpoints/best-0.000.pth\nEpoch 2/30\nEpoch 3/30\nEpoch 4/30\n保存新的最佳模型 checkpoints/best-0.667.pth\nEpoch 5/30\nEpoch 6/30\nEpoch 7/30\nEpoch 8/30\nEpoch 9/30\nEpoch 10/30\nEpoch 11/30\n保存新的最佳模型 checkpoints/best-0.698.pth\nEpoch 12/30\nEpoch 13/30\nEpoch 14/30\nEpoch 15/30\nEpoch 16/30\nEpoch 17/30\n保存新的最佳模型 checkpoints/best-0.743.pth\nEpoch 18/30\nEpoch 19/30\nEpoch 20/30\nEpoch 21/30\nEpoch 22/30\n保存新的最佳模型 checkpoints/best-0.747.pth\nEpoch 23/30\nEpoch 24/30\nEpoch 25/30\nEpoch 26/30\nEpoch 27/30\nEpoch 28/30\nEpoch 29/30\nEpoch 30/30\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": " 27%|██▋       | 17/63 [00:43<01:57,  2.56s/it]\n100%|██████████| 32/32 [02:11<00:00,  4.10s/it]\n100%|██████████| 32/32 [02:10<00:00,  4.09s/it]\n100%|██████████| 32/32 [01:48<00:00,  3.40s/it]\n100%|██████████| 32/32 [02:04<00:00,  3.88s/it]\n100%|██████████| 32/32 [01:56<00:00,  3.63s/it]\n100%|██████████| 32/32 [01:57<00:00,  3.66s/it]\n100%|██████████| 32/32 [01:48<00:00,  3.38s/it]\n100%|██████████| 32/32 [01:49<00:00,  3.42s/it]\n100%|██████████| 32/32 [01:47<00:00,  3.36s/it]\n100%|██████████| 32/32 [01:52<00:00,  3.51s/it]\n100%|██████████| 32/32 [01:47<00:00,  3.35s/it]\n100%|██████████| 32/32 [01:52<00:00,  3.53s/it]\n100%|██████████| 32/32 [01:47<00:00,  3.36s/it]\n100%|██████████| 32/32 [01:44<00:00,  3.27s/it]\n100%|██████████| 32/32 [01:47<00:00,  3.37s/it]\n100%|██████████| 32/32 [01:49<00:00,  3.43s/it]\n100%|██████████| 32/32 [01:53<00:00,  3.54s/it]\n100%|██████████| 32/32 [01:54<00:00,  3.57s/it]\n100%|██████████| 32/32 [01:50<00:00,  3.44s/it]\n100%|██████████| 32/32 [01:45<00:00,  3.29s/it]\n100%|██████████| 32/32 [01:54<00:00,  3.59s/it]\n100%|██████████| 32/32 [01:53<00:00,  3.54s/it]\n100%|██████████| 32/32 [01:45<00:00,  3.29s/it]\n100%|██████████| 32/32 [02:00<00:00,  3.78s/it]\n100%|██████████| 32/32 [01:54<00:00,  3.59s/it]\n100%|██████████| 32/32 [01:53<00:00,  3.54s/it]\n100%|██████████| 32/32 [01:52<00:00,  3.51s/it]\n100%|██████████| 32/32 [01:51<00:00,  3.48s/it]\n100%|██████████| 32/32 [01:56<00:00,  3.63s/it]\n100%|██████████| 32/32 [01:53<00:00,  3.56s/it]\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676015543563
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 载入最佳模型作为当前模型\n",
        "model = torch.load('checkpoints/best-{:.3f}.pth'.format(best_test_accuracy))"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676015545377
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "print(evaluate_testset())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'epoch': 30, 'test_loss': 0.32866967, 'test_accuracy': 0.76, 'test_precision': 0.6940990057372863, 'test_recall': 0.6821317500706813, 'test_f1-score': 0.6801095532438817}\n"
        }
      ],
      "execution_count": 21,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "gather": {
          "logged": 1676015645414
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}